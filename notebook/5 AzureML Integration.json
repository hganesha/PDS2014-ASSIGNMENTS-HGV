{
	"name": "5 AzureML Integration",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"language_info": {
				"name": "python"
			}
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"{\n",
					"  \"metadata\": {\n",
					"    \"saveOutput\": true,\n",
					"    \"language_info\": {\n",
					"      \"name\": \"python\"\n",
					"    }\n",
					"  },\n",
					"  \"nbformat\": 4,\n",
					"  \"nbformat_minor\": 2,\n",
					"  \"cells\": [\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"Copyright (c) Microsoft Corporation. \\n\",\n",
					"        \"Licensed under the MIT license. \\n\",\n",
					"        \"# Azure Machine Learning / AutoML Integration\\n\",\n",
					"        \"\\n\",\n",
					"        \"Capture results of AutoML experiments on the dataset and persist to Data Lake for reporting and analysis.\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Library Imports\\n\",\n",
					"        \"\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": 90,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"import azureml.core\\n\",\n",
					"        \"from azureml.core import Workspace, Datastore, Dataset, Run\\n\",\n",
					"        \"from azureml.core.run import Run\\n\",\n",
					"        \"from azureml.core.experiment import Experiment\\n\",\n",
					"        \"from azureml.core.model import Model\\n\",\n",
					"        \"from azureml.interpret import ExplanationClient\\n\",\n",
					"        \"from pyspark.sql.functions import *\\n\",\n",
					"        \"import pprint\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Read Model Metrics from Azure ML\\n\",\n",
					"        \"\\n\",\n",
					"        \"Connect to the Azure ML workspace and extract metrics from the AutoML run.\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": 87,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# connect to Azure ML\\n\",\n",
					"        \"subscription_id = ''\\n\",\n",
					"        \"workspace_name = ''\\n\",\n",
					"        \"resource_group = ''\\n\",\n",
					"        \"\\n\",\n",
					"        \"ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\\n\",\n",
					"        \"\\n\",\n",
					"        \"#pp = pprint.PrettyPrinter()\\n\",\n",
					"        \"#pp.pprint(ws.get_details())\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"### Pull Metrics from Run\\n\",\n",
					"        \"\\n\",\n",
					"        \"Gather the following metrics:\\n\",\n",
					"        \"\\n\",\n",
					"        \"* AUC = AUC_weighted\\n\",\n",
					"        \"* Accuracy = accuracy\\n\",\n",
					"        \"* Precision = precision_score_weighted\\n\",\n",
					"        \"* Recall = recall_score_weighted\\n\",\n",
					"        \"* F1 = f1_score_weighted\\n\",\n",
					"        \"\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": 88,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# pull all metrics of best run\\n\",\n",
					"        \"experiment_name = ''\\n\",\n",
					"        \"run_id = ''\\n\",\n",
					"        \"\\n\",\n",
					"        \"experiment = Experiment(workspace=ws, name=experiment_name)\\n\",\n",
					"        \"fetched_run = Run(experiment, run_id)\\n\",\n",
					"        \"metrics = fetched_run.get_metrics()\\n\",\n",
					"        \"\\n\",\n",
					"        \"#pp = pprint.PrettyPrinter()\\n\",\n",
					"        \"#pp.pprint(metrics)\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": 89,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {\n",
					"        \"diagram\": {\n",
					"          \"activateDiagramType\": 1,\n",
					"          \"chartConfig\": {\n",
					"            \"category\": \"bar\",\n",
					"            \"keys\": [\n",
					"              \"Metric\"\n",
					"            ],\n",
					"            \"values\": [\n",
					"              \"Value\"\n",
					"            ],\n",
					"            \"yLabel\": \"Value\",\n",
					"            \"xLabel\": \"Metric\",\n",
					"            \"aggregation\": \"SUM\",\n",
					"            \"aggByBackend\": false\n",
					"          },\n",
					"          \"aggData\": \"{\\\"Value\\\":{\\\"AUC\\\":0.7530583094702326,\\\"Accuracy\\\":0.6831256729733887,\\\"F1\\\":0.681859512812026,\\\"Precision\\\":0.682347667116298,\\\"Recall\\\":0.6831256729733887}}\",\n",
					"          \"isSummary\": false,\n",
					"          \"previewData\": {\n",
					"            \"filter\": null\n",
					"          },\n",
					"          \"isSql\": false\n",
					"        }\n",
					"      },\n",
					"      \"source\": [\n",
					"        \"# select relevant metrics\\n\",\n",
					"        \"auc = metrics.get('AUC_weighted')\\n\",\n",
					"        \"accuracy = metrics.get('accuracy')\\n\",\n",
					"        \"precision = metrics.get('precision_score_weighted')\\n\",\n",
					"        \"recall = metrics.get('recall_score_weighted')\\n\",\n",
					"        \"f1 = metrics.get('f1_score_weighted')\\n\",\n",
					"        \"\\n\",\n",
					"        \"# combine into single dataframe\\n\",\n",
					"        \"metrics_df = sc.parallelize([['AUC', auc], ['Accuracy', accuracy], ['Precision', precision], ['Recall', recall], ['F1', f1]]).toDF(('Metric', 'Value'))\\n\",\n",
					"        \"\\n\",\n",
					"        \"#display(metrics_df)\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Read Feature Importances from AutoML\\n\",\n",
					"        \"\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": 91,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"client = ExplanationClient.from_run(fetched_run)\\n\",\n",
					"        \"engineered_explanations = client.download_model_explanation(raw=False)\\n\",\n",
					"        \"features_dict = engineered_explanations.get_feature_importance_dict()\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": 92,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {\n",
					"        \"diagram\": {\n",
					"          \"activateDiagramType\": 1,\n",
					"          \"chartConfig\": {\n",
					"            \"category\": \"bar\",\n",
					"            \"keys\": [\n",
					"              \"Feature\"\n",
					"            ],\n",
					"            \"values\": [\n",
					"              \"Value\"\n",
					"            ],\n",
					"            \"yLabel\": \"Value\",\n",
					"            \"xLabel\": \"Feature\",\n",
					"            \"aggregation\": \"SUM\",\n",
					"            \"aggByBackend\": false\n",
					"          },\n",
					"          \"aggData\": \"{\\\"Value\\\":{\\\"avg_cart_abandon_rate_MeanImputer\\\":0.11945935832914051,\\\"avg_conversion_rate_per_user_per_month_MeanImputer\\\":0.20401384027776798,\\\"avg_order_value_per_user_per_month_MeanImputer\\\":0.41822444885119187,\\\"avg_session_duration_per_user_per_month_MeanImputer\\\":0.27078611121785473,\\\"brand_acer_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.0175239679182456,\\\"brand_apple_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.021093607022107382,\\\"brand_huawei_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.0026359798356834024,\\\"brand_samsung_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.008199318744508445,\\\"brand_xiaomi_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.009319515351190353,\\\"product_id_1004767_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.0006593092513365638,\\\"product_id_1004833_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.0008278505122272443,\\\"product_id_1004856_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.00024530348177285977,\\\"product_id_1005115_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.006105109365293523,\\\"product_id_4804056_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.0003915675165785674,\\\"sessions_per_user_per_month_MeanImputer\\\":0.40902442785462995,\\\"subcategory_audio_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.0859806049597816,\\\"subcategory_clocks_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.011233049590709289,\\\"subcategory_smartphone_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.011650992130277638,\\\"subcategory_tablet_purchased_binary_ModeCatImputer_LabelEncoder\\\":0,\\\"subcategory_telephone_purchased_binary_ModeCatImputer_LabelEncoder\\\":0.00031129917547430985}}\",\n",
					"          \"isSummary\": false,\n",
					"          \"previewData\": {\n",
					"            \"filter\": null\n",
					"          },\n",
					"          \"isSql\": false\n",
					"        }\n",
					"      },\n",
					"      \"source\": [\n",
					"        \"# save to list and convert numpy types to native\\n\",\n",
					"        \"features_list = []\\n\",\n",
					"        \"\\n\",\n",
					"        \"for key, value in features_dict.items():\\n\",\n",
					"        \"    temp = [key.item(),value.item()]\\n\",\n",
					"        \"    features_list.append(temp)\\n\",\n",
					"        \"\\n\",\n",
					"        \"# save to dataframe\\n\",\n",
					"        \"features_df = spark.createDataFrame(features_list, ['Feature', 'Value'])\\n\",\n",
					"        \"\\n\",\n",
					"        \"#display(features_df)\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Save Results to Data Lake\\n\",\n",
					"        \"\\n\",\n",
					"        \"Persist the model results to CSV files on the Data Lake for reporting.\\n\",\n",
					"        \"\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"data_lake_account_name = ''\\n\",\n",
					"        \"file_system_name = ''\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"metrics_df.coalesce(1).write.option('header', 'true').mode('overwrite').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/reporting/model_metrics')\\n\",\n",
					"        \"features_df.coalesce(1).write.option('header', 'true').mode('overwrite').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/reporting/feature_importances')\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    }\n",
					"  ]\n",
					"}"
				],
				"execution_count": null
			}
		]
	}
}