{
	"name": "2 Data Engineering",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"language_info": {
				"name": "python"
			}
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"{\n",
					"  \"metadata\": {\n",
					"    \"saveOutput\": true,\n",
					"    \"language_info\": {\n",
					"      \"name\": \"python\"\n",
					"    }\n",
					"  },\n",
					"  \"nbformat\": 4,\n",
					"  \"nbformat_minor\": 2,\n",
					"  \"cells\": [\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"Copyright (c) Microsoft Corporation. \\n\",\n",
					"        \"Licensed under the MIT license. \\n\",\n",
					"        \"# Data Engineering\\n\",\n",
					"        \"\\n\",\n",
					"        \"After cleaning the data, we transform it in order to capture relevant metrics for ML modeling. These metrics  capture information related to:\\n\",\n",
					"        \"* Users & sessions\\n\",\n",
					"        \"* Buying behavior\\n\",\n",
					"        \"* Product details - brand, category, subcategories, product\\n\",\n",
					"        \"\\n\",\n",
					"        \"Results are written to the delta lake.\\n\",\n",
					"        \"\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Library Imports\\n\",\n",
					"        \"\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"import pyspark\\n\",\n",
					"        \"from pyspark.sql import functions as F\\n\",\n",
					"        \"from pyspark.sql.functions import *\\n\",\n",
					"        \"from pyspark.sql import *\\n\",\n",
					"        \"from pyspark.sql.types import *\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Read in Data from Delta Lake\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"data_lake_account_name = ''\\n\",\n",
					"        \"file_system_name = ''\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"full_dataset = ''\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"paths = [f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/transformed_data/cleaned_data_electronics']\\n\",\n",
					"        \"full_dataset = spark.read.format(\\\"delta\\\").load(*paths)\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# add month & year, re-order columns\\n\",\n",
					"        \"cleaned_df = full_dataset.withColumn('month', month('event_time')) \\\\\\n\",\n",
					"        \"    .withColumn('year', year('event_time')) \\\\\\n\",\n",
					"        \"    .drop('category_code') \\\\\\n\",\n",
					"        \"    .select('user_id', 'year', 'month', 'event_type', 'product_id', 'category_id', 'category', 'subcategory', 'brand', 'price', 'user_session', 'event_time')\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# write cleaned_df table to an intermediate spark table\\n\",\n",
					"        \"cleaned_df.write.format(\\\"delta\\\").mode(\\\"overwrite\\\").option(\\\"overwriteSchema\\\", \\\"true\\\").save(f\\\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/intermediate_tables/cleaned_df\\\")\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# read cleaned_df table from intermediate spark table\\n\",\n",
					"        \"cleaned_df = spark.read.format(\\\"delta\\\").load(f\\\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/intermediate_tables/cleaned_df\\\")\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Data Transformation\\n\",\n",
					"        \"\\n\",\n",
					"        \"### Growth Indicator\\n\",\n",
					"        \"\\n\",\n",
					"        \"Classify customers as growth (1) or no growth (0) based on the month-over-month change in net revenue.\\n\",\n",
					"        \"\\n\",\n",
					"        \"1. Growth if there is a >10% net revenue increase\\n\",\n",
					"        \"1. No growth if there is a >10% net revenue decrease\\n\",\n",
					"        \"\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {\n",
					"        \"diagram\": {\n",
					"          \"activateDiagramType\": 1,\n",
					"          \"chartConfig\": {\n",
					"            \"category\": \"bar\",\n",
					"            \"keys\": [\n",
					"              \"user_id\"\n",
					"            ],\n",
					"            \"values\": [\n",
					"              \"year\"\n",
					"            ],\n",
					"            \"yLabel\": \"year\",\n",
					"            \"xLabel\": \"user_id\",\n",
					"            \"aggregation\": \"SUM\",\n",
					"            \"aggByBackend\": false\n",
					"          },\n",
					"          \"aggData\": \"{\\\"year\\\":{\\\"101875240\\\":2020,\\\"107620212\\\":2020,\\\"128968633\\\":2019,\\\"136662675\\\":2019,\\\"145611266\\\":2019}}\",\n",
					"          \"isSummary\": false,\n",
					"          \"previewData\": {\n",
					"            \"filter\": null\n",
					"          },\n",
					"          \"isSql\": false\n",
					"        }\n",
					"      },\n",
					"      \"source\": [\n",
					"        \"# get monthly revenue\\n\",\n",
					"        \"growth = cleaned_df.filter(col('event_type') == 'purchase') \\\\\\n\",\n",
					"        \"    .withColumn('revenue', cleaned_df['price'].cast('double'))\\\\\\n\",\n",
					"        \"    .groupBy('user_id', 'year', 'month') \\\\\\n\",\n",
					"        \"    .sum('revenue') \\\\\\n\",\n",
					"        \"    .withColumnRenamed('sum(revenue)', 'total_net_revenue') \\\\\\n\",\n",
					"        \"    .orderBy('user_id', 'year', 'month')\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {\n",
					"        \"diagram\": {\n",
					"          \"activateDiagramType\": 1,\n",
					"          \"chartConfig\": {\n",
					"            \"category\": \"bar\",\n",
					"            \"keys\": [\n",
					"              \"user_id\"\n",
					"            ],\n",
					"            \"values\": [\n",
					"              \"year\"\n",
					"            ],\n",
					"            \"yLabel\": \"year\",\n",
					"            \"xLabel\": \"user_id\",\n",
					"            \"aggregation\": \"SUM\",\n",
					"            \"aggByBackend\": false\n",
					"          },\n",
					"          \"aggData\": \"{\\\"year\\\":{\\\"430640726\\\":2020,\\\"436540545\\\":2020,\\\"461023190\\\":2019,\\\"476777607\\\":4039}}\",\n",
					"          \"isSummary\": false,\n",
					"          \"previewData\": {\n",
					"            \"filter\": null\n",
					"          },\n",
					"          \"isSql\": false\n",
					"        }\n",
					"      },\n",
					"      \"source\": [\n",
					"        \"# get deltas for previous month\\n\",\n",
					"        \"from pyspark.sql.window import Window\\n\",\n",
					"        \"from pyspark.sql.functions import lag\\n\",\n",
					"        \"\\n\",\n",
					"        \"window_specs = Window.partitionBy('user_id').orderBy('user_id', 'year', 'month')\\n\",\n",
					"        \"\\n\",\n",
					"        \"growth_lag = growth.withColumn('last_month_revenue', lag(growth.total_net_revenue).over(window_specs).cast('double'))\\n\",\n",
					"        \"growth_delta = growth_lag.withColumn('delta_net_revenue', (growth_lag.total_net_revenue - growth_lag.last_month_revenue).cast('double'))\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# identify growth vs. no growth customers\\n\",\n",
					"        \"# growth defined as +/-10% revenue month-over-month\\n\",\n",
					"        \"\\n\",\n",
					"        \"df_growth_a = growth_delta.withColumn('percent_delta_revenue', growth_delta['delta_net_revenue']/growth_delta['last_month_revenue'].cast('double'))\\n\",\n",
					"        \"df_growth = df_growth_a.withColumn('growth', \\n\",\n",
					"        \"        when(df_growth_a['percent_delta_revenue'] > .1, 1)\\n\",\n",
					"        \"        .when(df_growth_a['percent_delta_revenue'] < -.1, 0)) \\\\\\n\",\n",
					"        \"        .drop('last_month_revenue', 'delta_net_revenue', 'total_net_revenue', 'percent_delta_revenue') \\\\\\n\",\n",
					"        \"        .filter(col('growth').isNotNull())\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Aggregated Metrics\\n\",\n",
					"        \"\\n\",\n",
					"        \"Transform data to produce metrics related to user sessions, buying behavior, and product categories. All features are aggregated on a per-user, per-month basis.\\n\",\n",
					"        \"\\n\",\n",
					"        \"### Session & Buying Metrics\\n\",\n",
					"        \"\\n\",\n",
					"        \"* Number of sessions\\n\",\n",
					"        \"* Average session duration\\n\",\n",
					"        \"* Average conversion rate\\n\",\n",
					"        \"* Average order value\\n\",\n",
					"        \"* Average cart abandon rate\\n\",\n",
					"        \"\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# sessions per user\\n\",\n",
					"        \"sessions_per_user_per_month = cleaned_df.groupBy('user_id', 'year', 'month') \\\\\\n\",\n",
					"        \"    .agg(countDistinct('user_session').alias('sessions_per_user_per_month')) \\\\\\n\",\n",
					"        \"    .fillna({'sessions_per_user_per_month': 0}) \\\\\\n\",\n",
					"        \"    .orderBy('user_id', 'year', 'month')\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# avg session duration\\n\",\n",
					"        \"# time between start & end of each session, aggregated per user per month\\n\",\n",
					"        \"session_durations = cleaned_df.groupBy('user_id', 'year', 'month', 'user_session') \\\\\\n\",\n",
					"        \"    .agg(\\n\",\n",
					"        \"        unix_timestamp(min('event_time')).alias('session_start_time'),\\n\",\n",
					"        \"        unix_timestamp(max('event_time')).alias('session_end_time')) \\\\\\n\",\n",
					"        \"    .withColumn('session_duration', col('session_end_time')-col('session_start_time')) \\\\\\n\",\n",
					"        \"    .drop('user_session', 'session_start_time', 'session_end_time')\\n\",\n",
					"        \"\\n\",\n",
					"        \"avg_session_duration_per_user_per_month = session_durations.groupBy('user_id', 'year', 'month') \\\\\\n\",\n",
					"        \"    .agg(mean('session_duration').cast('double').alias('avg_session_duration_per_user_per_month')) \\\\\\n\",\n",
					"        \"    .orderBy('user_id', 'year', 'month')\\n\",\n",
					"        \"\\n\",\n",
					"        \"#avg_session_duration_per_user_per_month.orderBy(desc('avg_session_duration_per_user_per_month')).show(5)\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# avg conversion rate\\n\",\n",
					"        \"# avg # purchases / # views per user per month\\n\",\n",
					"        \"avg_conversion_rate_per_user_per_month = cleaned_df.groupBy('user_id', 'year', 'month') \\\\\\n\",\n",
					"        \"    .agg(\\n\",\n",
					"        \"        count(when(col('event_type') == 'view', True)).alias('num_views'),\\n\",\n",
					"        \"        count(when(col('event_type') == 'purchase', True)).alias('num_purchases')) \\\\\\n\",\n",
					"        \"    .fillna({'num_views': 0, 'num_purchases': 0}) \\\\\\n\",\n",
					"        \"    .withColumn('avg_conversion_rate_per_user_per_month', (col('num_purchases')/col('num_views')).cast('double')) \\\\\\n\",\n",
					"        \"    .drop('num_views', 'num_purchases') \\\\\\n\",\n",
					"        \"    .orderBy('user_id', 'year', 'month')\\n\",\n",
					"        \"\\n\",\n",
					"        \"#avg_conversion_rate_per_user_per_month.orderBy(desc('avg_conversion_rate_per_user_per_month')).show(5)\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# avg order value\\n\",\n",
					"        \"# price per user per month, for purchases only\\n\",\n",
					"        \"avg_order_value_per_user_per_month = cleaned_df.filter(col('event_type') == 'purchase') \\\\\\n\",\n",
					"        \"    .groupBy('user_id', 'year', 'month') \\\\\\n\",\n",
					"        \"    .agg(mean('price').cast('double').alias('avg_order_value_per_user_per_month')) \\\\\\n\",\n",
					"        \"    .orderBy('user_id', 'year', 'month')\\n\",\n",
					"        \"\\n\",\n",
					"        \"#avg_order_value_per_user_per_month.show(5)\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# avg_cart_abandon_rate\\n\",\n",
					"        \"# items that were added to cart, but not purchased\\n\",\n",
					"        \"abandon_rate_per_session = cleaned_df.filter((col('event_type') == 'purchase') | (col('event_type') == 'cart')) \\\\\\n\",\n",
					"        \"    .groupBy('user_id', 'year', 'month', 'user_session', 'product_id') \\\\\\n\",\n",
					"        \"    .pivot('event_type').agg(count('product_id')) \\\\\\n\",\n",
					"        \"    .fillna({'cart':0, 'purchase':0}) \\\\\\n\",\n",
					"        \"    .withColumn('cart_abandon_rate', (col('cart')-col('purchase'))/col('cart'))\\n\",\n",
					"        \"\\n\",\n",
					"        \"avg_cart_abandon_rate = abandon_rate_per_session.groupBy('user_id', 'year', 'month') \\\\\\n\",\n",
					"        \"    .agg(mean('cart_abandon_rate').cast('double').alias('avg_cart_abandon_rate'))\\n\",\n",
					"        \"\\n\",\n",
					"        \"#avg_cart_abandon_rate.show(5)\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"### Brand, Subcategory, & Product Metrics\\n\",\n",
					"        \"\\n\",\n",
					"        \"For the top 5 most popular values in each product-related category (brand, subcategory, and product_id), identify the frequency of user clickstream interactions (product views, add to cart, and purchases).\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {\n",
					"        \"diagram\": {\n",
					"          \"activateDiagramType\": 1,\n",
					"          \"chartConfig\": {\n",
					"            \"category\": \"bar\",\n",
					"            \"keys\": [\n",
					"              \"user_id\"\n",
					"            ],\n",
					"            \"values\": [\n",
					"              \"year\"\n",
					"            ],\n",
					"            \"yLabel\": \"year\",\n",
					"            \"xLabel\": \"user_id\",\n",
					"            \"aggregation\": \"SUM\",\n",
					"            \"aggByBackend\": false\n",
					"          },\n",
					"          \"aggData\": \"{\\\"year\\\":{\\\"104655840\\\":2020,\\\"113868975\\\":2020,\\\"120701478\\\":4040,\\\"128968633\\\":6060,\\\"138365902\\\":2019,\\\"153449371\\\":4039,\\\"158131855\\\":2020,\\\"158971609\\\":2019,\\\"191365178\\\":2019,\\\"191555348\\\":2020,\\\"195082191\\\":2019}}\",\n",
					"          \"isSummary\": false,\n",
					"          \"previewData\": {\n",
					"            \"filter\": null\n",
					"          },\n",
					"          \"isSql\": false\n",
					"        }\n",
					"      },\n",
					"      \"source\": [\n",
					"        \"# reusable function\\n\",\n",
					"        \"## event_type = clickstream activity (view, cart, purchase)\\n\",\n",
					"        \"## match_type = product-related column (brand, subcategory, product_id)\\n\",\n",
					"        \"\\n\",\n",
					"        \"def get_top_5(df, event_type, match_type):\\n\",\n",
					"        \"\\n\",\n",
					"        \"    # get list of top 5\\n\",\n",
					"        \"    top_5_list = df.filter(col('event_type')==event_type).groupBy(match_type).pivot('event_type') \\\\\\n\",\n",
					"        \"        .agg(count('user_session')).orderBy(desc(event_type)) \\\\\\n\",\n",
					"        \"        .select(match_type).limit(5).rdd.flatMap(lambda x: x).collect()\\n\",\n",
					"        \"        \\n\",\n",
					"        \"    # filter df for top 5\\n\",\n",
					"        \"    top_5_df = df.where(col(match_type).isin(top_5_list)) \\\\\\n\",\n",
					"        \"        .filter(col('event_type')==event_type) \\\\\\n\",\n",
					"        \"        .groupBy('user_id', 'year', 'month') \\\\\\n\",\n",
					"        \"        .pivot(match_type) \\\\\\n\",\n",
					"        \"        .agg(count('user_session'))\\n\",\n",
					"        \"\\n\",\n",
					"        \"    # reformat types / naming convention\\n\",\n",
					"        \"    if (event_type == 'view'):\\n\",\n",
					"        \"        event_type = 'viewed'\\n\",\n",
					"        \"    elif (event_type == 'cart'):\\n\",\n",
					"        \"        event_type = 'added'\\n\",\n",
					"        \"    else:\\n\",\n",
					"        \"        event_type = 'purchased'\\n\",\n",
					"        \"\\n\",\n",
					"        \"    # convert to binary & count columns\\n\",\n",
					"        \"    for i in range(1, len(top_5_list)+1):\\n\",\n",
					"        \"        i_name = top_5_list[i-1]\\n\",\n",
					"        \"        top_5_df = top_5_df.withColumn(f'{match_type}_{i_name}_{event_type}_binary', when(col(i_name).isNotNull(), 1).otherwise(0)) \\\\\\n\",\n",
					"        \"            .withColumnRenamed(f'{i_name}', f'{match_type}_{i_name}_{event_type}_count') \\\\\\n\",\n",
					"        \"            .fillna({f'{match_type}_{i_name}_{event_type}_count': 0})\\n\",\n",
					"        \"\\n\",\n",
					"        \"    return top_5_df\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# brands\\n\",\n",
					"        \"top_brands_viewed = get_top_5(cleaned_df, 'view', 'brand')\\n\",\n",
					"        \"top_brands_added = get_top_5(cleaned_df, 'cart', 'brand')\\n\",\n",
					"        \"top_brands_purchased = get_top_5(cleaned_df, 'purchase', 'brand')\\n\",\n",
					"        \"\\n\",\n",
					"        \"# subcategories\\n\",\n",
					"        \"top_subcategories_viewed = get_top_5(cleaned_df, 'view', 'subcategory')\\n\",\n",
					"        \"top_subcategories_added = get_top_5(cleaned_df, 'cart', 'subcategory')\\n\",\n",
					"        \"top_subcategories_purchased = get_top_5(cleaned_df, 'purchase', 'subcategory')\\n\",\n",
					"        \"\\n\",\n",
					"        \"# products\\n\",\n",
					"        \"top_products_viewed = get_top_5(cleaned_df, 'view', 'product_id')\\n\",\n",
					"        \"top_products_added = get_top_5(cleaned_df, 'cart', 'product_id')\\n\",\n",
					"        \"top_products_purchased = get_top_5(cleaned_df, 'purchase', 'product_id')\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Join DataFrames into Single DataFrame\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# join dfs\\n\",\n",
					"        \"def join_dfs (df_list):\\n\",\n",
					"        \"    joined_df = df_growth\\n\",\n",
					"        \"    for l in df_list:\\n\",\n",
					"        \"        joined_df = joined_df.join(l, ['user_id', 'year', 'month'], how='left')\\n\",\n",
					"        \"    return joined_df\\n\",\n",
					"        \"\\n\",\n",
					"        \"features_df = join_dfs([sessions_per_user_per_month, \\\\\\n\",\n",
					"        \"    avg_session_duration_per_user_per_month, \\\\\\n\",\n",
					"        \"    avg_conversion_rate_per_user_per_month, \\\\\\n\",\n",
					"        \"    avg_order_value_per_user_per_month, \\\\\\n\",\n",
					"        \"    avg_cart_abandon_rate, \\\\\\n\",\n",
					"        \"    top_brands_viewed, top_brands_added, top_brands_purchased, \\\\\\n\",\n",
					"        \"    top_subcategories_viewed, top_subcategories_added, top_subcategories_purchased, \\\\\\n\",\n",
					"        \"    top_products_viewed, top_products_added, top_products_purchased\\n\",\n",
					"        \"    ]).fillna(0)\\n\",\n",
					"        \"\\n\",\n",
					"        \"# display(features_df.take(15))\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"markdown\",\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"## Save Transformed Data to a Delta Table\\n\",\n",
					"        \"\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    },\n",
					"    {\n",
					"      \"cell_type\": \"code\",\n",
					"      \"execution_count\": null,\n",
					"      \"outputs\": [],\n",
					"      \"metadata\": {},\n",
					"      \"source\": [\n",
					"        \"# write transformed data to spark table\\n\",\n",
					"        \"features_df.write.format('delta').mode('overwrite').option(\\\"overwriteSchema\\\", \\\"true\\\").save(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/transformed_data/transformed_data')\"\n",
					"      ],\n",
					"      \"attachments\": {}\n",
					"    }\n",
					"  ]\n",
					"}"
				],
				"execution_count": null
			}
		]
	}
}